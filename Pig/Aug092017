##Load data into a Pig relation without a schema
station = LOAD '/user/ingenieroandresangel/datasets/stations_nh.csv' USING PigStorage(',');

##Load data into a Pig relation with a schema
station_s = LOAD '/user/ingenieroandresangel/datasets/stations_nh.csv' USING PigStorage(',')
AS (code:int,name:chararray,la:double,lo:double);


##Load data from a Hive table into a Pig relation
july = LOAD 'POC.july' USING org.apache.hive.hcatalog.pig.HCatLoader ;

##Use Pig to transform data into a specified format
july_cl = FOREACH july GENERATE GetDay(ToDate(start_date)) as day:int,start_station,duration;
jul_cl_fl = FILTER july_cl BY day==31;
july_gr = GROUP jul_cl_fl BY (day,start_station);
july_result = FOREACH july_gr {
              total_dura = SUM(jul_cl_fl.duration);
              avg_dura = AVG(jul_cl_fl.duration);
              qty_trips = COUNT(jul_cl_fl);
              GENERATE FLATTEN(group),total_dura,avg_dura,qty_trips;
              };
              
##Transform data to match a given Hive schema
orders = LOAD 'hdfs://nn01.itversity.com:8020/apps/hive/warehouse/poc.db/orders'  USING PigStorage('\u0001')
AS (order_id:int,order_date:chararray,order_customer_id:int,order_status:chararray);

##Group the data of one or more Pig relations
july_cogr = COGROUP jul_cl_fl BY start_station, station_s BY code;
july_cogr_resu = FOREACH july_cogr {
            qty_trips = COUNT(jul_cl_fl);
            GENERATE group,FLATTEN(station_s.name),qty_trips;
            };

##Use Pig to remove records with null values from a relation
duplicates = LOAD '/user/ingenieroandresangel/datasets/duplicates.csv' USING PigStorage(',')
AS (id:int,brand:chararray,city:chararray,country:chararray,value:double);

duplicates_cl = FILTER duplicates BY (city IS NOT NULL) AND (value IS NOT NULL); 

##Store the data from a Pig relation into a folder in HDFS
STORE july_cogr_resu INTO '/user/ingenieroandresangel/sqoop/result' USING PigStorage(',');


##Store the data from a Pig relation into a Hive table
--Table must exist before
july_result = FOREACH july_gr {
              total_dura = SUM(jul_cl_fl.duration);
              avg_dura = AVG(jul_cl_fl.duration);
              qty_trips = COUNT(jul_cl_fl);
              GENERATE FLATTEN(group) as (day:int),total_dura as (total_dura:int),avg_dura as (avg_dura:int),qty_trips as (qty_trips:int);
              };

STORE july_result INTO 'poc.july_analysis' USING org.apache.hive.hcatalog.pig.HCatStorer (); 

STORE duplicates_cl INTO 'poc.cars' USING org.apache.hive.hcatalog.pig.HCatStorer (); 

CREATE EXTERNAL TABLE july_analysis
(day int,duration double,avg_duration double,trips int)
STORED AS TEXTFILE
LOCATION '/user/ingenieroandresangel/hive/july_analysis';

## Sort the output of a Pig relation

order_july = ORDER jul_cl_fl BY duration DESC;

## Remove the duplicate tuples of a Pig relation

cars_nonduplicates = DISTINCT duplicates_cl;

## Specify the number of reduce tasks for a Pig MapReduce job
set default_parallel 2;

## Join two datasets using Pig

join_julycar = JOIN jul_cl_fl by  start_station , station_s by code;
left_julycar = JOIN jul_cl_fl by  start_station LEFT OUTER, station_s by code;
right_julycar = JOIN jul_cl_fl by  start_station RIGHT OUTER, station_s by code;

## Perform a replicated join using Pig
-- replicated just available for LEFT and INNER
left_julycar = JOIN jul_cl_fl by  start_station LEFT OUTER, station_s by code using 'replicated';
join_julycar = JOIN jul_cl_fl by  start_station , station_s by code using 'replicated';


## Run a Pig job using Tez

Pig -x Tez

## Within a Pig script, register a JAR file of User Defined Functions
## Within a Pig script, define an alias for a User Defined Function
## Within a Pig script, invoke a User Defined Function
set default_parallel 3;
REGISTER '/home/ingenieroandresangel/piggybank-0.12.0.jar';
DEFINE andy_lower org.apache.pig.piggybank.evaluation.string.LOWER;

station_s = LOAD '/user/ingenieroandresangel/datasets/stations_nh.csv' USING PigStorage(',')
AS (code:int,name:chararray,la:double,lo:double);

result = FOREACH station_s GENERATE code,andy_lower(name);
dump result;


















